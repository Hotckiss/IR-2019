{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import parallel_bulk\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time\n",
    "from lxml import etree\n",
    "from sklearn.metrics import r2_score\n",
    "from datetime import timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_es_action(index, doc_id, document):\n",
    "    return {\n",
    "        '_index': index,\n",
    "        '_id': doc_id,\n",
    "        '_source': document\n",
    "    }\n",
    "\n",
    "def pretty_print_result(search_result, fields=None):\n",
    "    if fields is None:\n",
    "        fields = []\n",
    "    res = search_result['hits']\n",
    "    print(f'Total documents: {res[\"total\"][\"value\"]}')\n",
    "    for hit in res['hits']:\n",
    "        print(f'Doc {hit[\"_id\"]}, score is {hit[\"_score\"]}')\n",
    "        for field in fields:\n",
    "            print(f'{field}: {hit[\"_source\"][field]}')\n",
    "\n",
    "\n",
    "def get_score(search_result):\n",
    "    res = []\n",
    "    for hit in search_result['hits']['hits']:\n",
    "        res.append((hit[\"_id\"], hit[\"_score\"]))\n",
    "    res.sort(key = lambda x: x[1], reverse = True)\n",
    "    return res\n",
    "\n",
    "\n",
    "class Index:\n",
    "    def __init__(self, index, settings):\n",
    "        self.index_name = index\n",
    "        self.settings = settings\n",
    "        self.es = Elasticsearch([{'host': 'localhost', 'port': 9200, 'timeout': 360}])\n",
    "        if self.es.indices.exists(index=index):\n",
    "            self.es.indices.delete(index=index)\n",
    "        self.es.indices.create(index=index, body=settings)\n",
    "\n",
    "    def es_actions_generator(self, path_to_docs):\n",
    "        for doc_name in tqdm(os.listdir(path_to_docs)):\n",
    "            with open(f\"{path_to_docs}/{doc_name}\", \"r\", encoding=\"utf-8\") as inf:\n",
    "                doc_id = int(''.join(list(filter(str.isdigit, doc_name))))\n",
    "                doc = json.load(inf)           \n",
    "            yield create_es_action(self.index_name, doc_id, doc)\n",
    "\n",
    "\n",
    "    def add_documents(self, path_to_docs):\n",
    "        try:\n",
    "            for ok, result in parallel_bulk(self.es, self.es_actions_generator(path_to_docs), queue_size=4, thread_count=4,\n",
    "                                        chunk_size=1000):\n",
    "                  if not ok:\n",
    "                     print(result)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "\n",
    "    def get_doc_by_id(self, doc_id):\n",
    "        return self.es.get(index=self.index_name, id=doc_id)['_source']\n",
    "\n",
    "    def search(self, query, *args):\n",
    "        return self.es.search(index=self.index_name, body=query, size=20)\n",
    "        # note that size set to 20 just because default value is 10 and we know that we have 12 docs and 10 < 12 < 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_1 = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\n",
    "                \"type\": \"text\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "        'mappings': {\n",
    "            'properties': {\n",
    "                'text': {\n",
    "                    'type': 'text',\n",
    "                    'analyzer': 'russian_complex',\n",
    "                    'search_analyzer': 'russian_complex'\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        },\n",
    "        \"settings\": {\n",
    "        \"analysis\" : {\n",
    "            \"analyzer\" : {\n",
    "                \"my_analyzer\" : {\n",
    "                    \"tokenizer\" : \"standard\",\n",
    "                    \"filter\" : [\"lowercase\", \"russian_snow\", \"english_snow\"]\n",
    "                },\n",
    "                'russian_complex': {\n",
    "                    'char_filter': [\n",
    "                        'yont'\n",
    "                    ],\n",
    "                    'tokenizer': 'word_longer_2',\n",
    "                    'filter': [\n",
    "                        'lowercase',\n",
    "                        'russian_snow'\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            'char_filter': {\n",
    "                'yont': {\n",
    "                    'type': 'mapping',\n",
    "                    'mappings': [\n",
    "                        'ё => е'\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            'tokenizer': {\n",
    "                'word_longer_2': {\n",
    "                    'type': 'pattern',\n",
    "                    'pattern': '[a-zA-Z_0-9\\u0400-\\u04FF]{2,}',\n",
    "                    'group': 0\n",
    "                },\n",
    "                'white_20': {\n",
    "                    'type': 'whitespace',\n",
    "                    'max_token_length': 5\n",
    "                }\n",
    "            },\n",
    "            \"filter\" : {\n",
    "                \"russian_snow\" : {\n",
    "                    \"type\" : \"snowball\",\n",
    "                    \"language\" : \"Russian\"\n",
    "                },\n",
    "                \"english_snow\" : {\n",
    "                    \"type\" : \"snowball\",\n",
    "                    \"language\" : \"English\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = Index(\"docs\", settings_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "index.add_documents(\"res/json\")\n",
    "elapsed = time.time() - start\n",
    "print(str(timedelta(seconds=elapsed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_index = Index('stem_docs', settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "stem_index.add_documents(\"res/json\")\n",
    "elapsed = time.time() - start\n",
    "print(str(timedelta(seconds=elapsed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_index.get_doc_by_id('1000039')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query:\n",
    "    def __init__(self, task_id, query, relevant_docs):\n",
    "        self.task_id = task_id\n",
    "        self.query = query\n",
    "        self.relevant_docs = relevant_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def json_query(query):\n",
    "    return {\n",
    "    'query': {\n",
    "        'bool': {\n",
    "            'should': [\n",
    "                {\n",
    "                    'match': {\n",
    "                        'text': query.query\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank_query(query):\n",
    "    return  {\n",
    "    'query': {\n",
    "        'bool': {\n",
    "            'should': [\n",
    "                {\n",
    "                    'match': {\n",
    "                        'text': query.query\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'rank_feature': {\n",
    "                        'field': 'pagerank',\n",
    "                        'saturation': {\n",
    "                            'pivot': 10\n",
    "                        },\n",
    "                        'boost': '5.0'\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self, p, r, r_precision, map_score):\n",
    "        self.r = r\n",
    "        self.p = p\n",
    "        self.r_precision = r_precision\n",
    "        self.map_score = map_score\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"r = {self.r}\\np = {self.p}\\nr_precision = {self.r_precision}\\nMAP = {self.map_score}\"\n",
    "    \n",
    "    __repr__ = __str__\n",
    "\n",
    "\n",
    "class SearchQualityChecker:\n",
    "    def __init__(self, queries, index):\n",
    "        self.queries = queries\n",
    "        self.index = index\n",
    "        self.results = {}\n",
    "        self.metrics = {}\n",
    "        \n",
    "    def get_results(self, get_query=json_query):\n",
    "        r_precision_total = 0\n",
    "        map_score_total = 0\n",
    "        r_total = 0\n",
    "        p_total = 0\n",
    "        for q in tqdm(self.queries):\n",
    "            res = self.index.search(get_query(q))\n",
    "            print(q.task_id)\n",
    "            pretty_print_result(res)\n",
    "            scores = get_score(res)\n",
    "            metric = Metrics(p=self.p(20, q, scores), r=self.r(20, q, scores), r_precision=self.r_precision(q, scores),\n",
    "                            map_score=self.map_score(q, scores, 20))\n",
    "            p_total += metric.p\n",
    "            r_total += metric.r\n",
    "            r_precision_total += metric.r_precision\n",
    "            map_score_total += metric.map_score\n",
    "            self.metrics[q.task_id] = metric\n",
    "        Q = len(self.queries)\n",
    "        print(Q)\n",
    "        return Metrics(p=p_total / Q, r=r_total / Q, r_precision=r_precision_total / Q, map_score=map_score_total / Q)\n",
    "    \n",
    "    def r_precision(self, query, search_res_score):\n",
    "        return self.r(len(query.relevant_docs), query, search_res_score)\n",
    "    \n",
    "    def map_score(self, query, search_res_score, n):\n",
    "        m = 0\n",
    "        for k in range(1, n):       \n",
    "            m += self.p(k, query, search_res_score)\n",
    "        R = len(query.relevant_docs)\n",
    "        return m / n\n",
    "    \n",
    "    def p(self, k, query, search_res_score):\n",
    "        r = 0\n",
    "        for doc, _ in search_res_score[:k]:\n",
    "            if doc in query.relevant_docs:\n",
    "                r += 1\n",
    "        return r / k\n",
    "    \n",
    "    def r(self, k, query, search_res_score):\n",
    "        R = len(query.relevant_docs)\n",
    "        r = 0\n",
    "        for doc, _ in search_res_score[:k]:\n",
    "            if doc in query.relevant_docs:\n",
    "                r += 1\n",
    "        return r / R if R != 0 else 0 if len(search_res_score) > 0 else 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff_metrics(quality_checker, other_checker, k=20, comp=lambda x : x.map_score):\n",
    "     res = []\n",
    "     for task_id in quality_checker.metrics:\n",
    "        metric = quality_checker.metrics[task_id]\n",
    "        other_metric = other_checker.metrics[task_id]\n",
    "        res.append((task_id, abs(comp(metric) - comp(other_metric)), metric, other_metric))\n",
    "     res.sort(reverse=True, key=lambda x: x[1])\n",
    "     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevance():\n",
    "    res = {}\n",
    "    xml_tree = etree.parse(\"data/or_relevant-minus_table.xml\")\n",
    "    root = xml_tree.getroot()\n",
    "    for task in root.getchildren():\n",
    "        relevant_docs = set()\n",
    "        for document in task.getchildren():\n",
    "            if document.get(\"relevance\") == \"vital\":\n",
    "                relevant_docs.add(document.get(\"id\"))\n",
    "        res[task.get(\"id\")] = relevant_docs\n",
    "    print(len(res))\n",
    "    return res\n",
    "\n",
    "\n",
    "def generate_queries_plain_texts():\n",
    "    relevances = get_relevance()\n",
    "    xml_tree = etree.parse(\"data/web2008_adhoc.xml\")\n",
    "    root = xml_tree.getroot()\n",
    "    res = []\n",
    "    for task in root.getchildren():\n",
    "        if task.get(\"id\") is not None:\n",
    "            for query_text in task.getchildren():\n",
    "                try:\n",
    "                    res.append(Query(task.get(\"id\"), query_text.text, relevances[task.get(\"id\")]))\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "    print(len(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#queries = generate_queries_plain_texts()\n",
    "#print(queries)\n",
    "quality_checker = SearchQualityChecker(queries, index)\n",
    "plain_text_res = quality_checker.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_text_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "english_stopwords = stopwords.words(\"english\")\n",
    "black_list = [\"°\", \"№\", \"©\", \"...\", \"//\", \"://\", \"</\", \"\\\">\", \"=\\\"\", \"=\\'\", \"\\r\", \"\\n\", \"\\t\"]\n",
    "stem = Mystem()\n",
    "\n",
    "def lemmatize(text):\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    tokens = []\n",
    "    for word in words:\n",
    "        tokens.extend(stem.lemmatize(word))\n",
    "    tokens = [token for token in tokens if token != \" \" and token.strip() not in punctuation \\\n",
    "              and token not in russian_stopwords and token not in english_stopwords \\\n",
    "              and token not in black_list \\\n",
    "              and token.find(\"\\r\") == -1 \\\n",
    "              and token.find(\"\\n\") == -1 \\\n",
    "              and token.find(\"\\t\") == -1 \\\n",
    "              and not (token.isdigit() and len(token) == 1)]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def generate_queries_lemmas():\n",
    "    relevances = get_relevance()\n",
    "    xml_tree = etree.parse(\"data/web2008_adhoc.xml\")\n",
    "    root = xml_tree.getroot()\n",
    "    res = []\n",
    "    for task in tqdm(root.getchildren()):\n",
    "        if task.get(\"id\") is not None:\n",
    "            for query_text in task.getchildren():\n",
    "                try:\n",
    "                    res.append(Query(task.get(\"id\"), lemmatize(query_text.text), relevances[task.get(\"id\")]))\n",
    "                except:\n",
    "                    pass\n",
    "    print(len(res))\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_lemmas = generate_queries_lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_lemmas[8].query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_index = Index(\"lemma_docs\", settings_1)\n",
    "\n",
    "start = time.time()\n",
    "lemma_index.add_documents(\"data/json_filtered_tokens_texts\")\n",
    "elapsed = time.time() - start\n",
    "print(str(timedelta(seconds=elapsed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_quality_checker = SearchQualityChecker(queries_lemmas, lemma_index)\n",
    "lemma_res = lemma_quality_checker.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_diff_metrics(quality_checker, lemma_quality_checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_pagerank = {}\n",
    "with open('res/pagerank.txt','r') as f:\n",
    "    for line in f:\n",
    "        docId, docURL, rank = line.split()\n",
    "        id_to_pagerank[int(docId)] = float(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(id_to_pagerank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for doc_name in tqdm(os.listdir(\"data/json_filtered_tokens_texts\")):\n",
    "        with open(f\"data/json_filtered_tokens_texts/{doc_name}\", \"r+\", encoding=\"utf-8\") as inf:\n",
    "            doc_id = int(''.join(list(filter(str.isdigit, doc_name))))\n",
    "            doc = json.load(inf)\n",
    "            try:\n",
    "                doc[\"pagerank\"] = id_to_pagerank.get(doc_id)\n",
    "            except:\n",
    "                pass\n",
    "            inf.seek(0)        # <--- should reset file position to the beginning.\n",
    "            json.dump(doc, inf, indent=4, ensure_ascii=False)\n",
    "            inf.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_with_pagerank = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"pagerank\": {\n",
    "                \"type\": \"rank_feature\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_index = Index(\"pagerank_index\", settings_with_pagerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_index.add_documents(\"data/json_filtered_tokens_texts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_quality_checker = SearchQualityChecker(queries_lemmas, pr_index)\n",
    "pr_res = pr_quality_checker.get_results(pagerank_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_index.get_doc_by_id(1000039)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_titles = {\n",
    "        'mappings': {\n",
    "            'properties': {\n",
    "                'content': {\n",
    "                    'type': 'text',\n",
    "                },\n",
    "                'title': {\n",
    "                    'type': 'text'\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        }\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

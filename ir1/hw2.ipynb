{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\olga\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (4.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in c:\\users\\olga\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (7.0.4)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\olga\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from elasticsearch) (1.24.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml\n",
    "!pip install elasticsearch\n",
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import parallel_bulk\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time\n",
    "from lxml import etree\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_es_action(index, doc_id, document):\n",
    "    return {\n",
    "        '_index': index,\n",
    "        '_id': doc_id,\n",
    "        '_source': document\n",
    "    }\n",
    "\n",
    "def pretty_print_result(search_result, fields=None):\n",
    "    if fields is None:\n",
    "        fields = []\n",
    "    res = search_result['hits']\n",
    "    print(f'Total documents: {res[\"total\"][\"value\"]}')\n",
    "    for hit in res['hits']:\n",
    "        print(f'Doc {hit[\"_id\"]}, score is {hit[\"_score\"]}')\n",
    "        for field in fields:\n",
    "            print(f'{field}: {hit[\"_source\"][field]}')\n",
    "\n",
    "\n",
    "def get_score(search_result):\n",
    "    res = {}\n",
    "    for hit in search_result['hits']['hits']:\n",
    "        res[hit[\"_id\"]] = hit[\"_score\"]\n",
    "    return res\n",
    "\n",
    "\n",
    "class Index:\n",
    "    def __init__(self, index, settings):\n",
    "        self.index_name = index\n",
    "        self.settings = settings\n",
    "        self.es = Elasticsearch([{'host': 'localhost', 'port': 9200, 'timeout': 360}])\n",
    "        if not self.es.indices.exists(index=index):\n",
    "            self.es.indices.create(index=index, body=settings)\n",
    "\n",
    "    def es_actions_generator(self):\n",
    "        for doc_name in tqdm(os.listdir(\"D:\\\\IR-2019\\\\ir1\\\\res\\\\json\")):\n",
    "            with open(f\"D:\\\\IR-2019\\\\ir1\\\\res\\\\json\\\\{doc_name}\", \"r\", encoding=\"utf-8\") as inf:\n",
    "                doc_id = int(''.join(list(filter(str.isdigit, doc_name))))\n",
    "                doc = json.load(inf)\n",
    "            yield create_es_action(self.index_name, doc_id, doc)\n",
    "\n",
    "    def add_documents(self):\n",
    "        for ok, result in parallel_bulk(self.es, self.es_actions_generator(), queue_size=4, thread_count=4,\n",
    "                                        chunk_size=1000):\n",
    "            if not ok:\n",
    "                print(result)\n",
    "\n",
    "    def get_doc_by_id(self, doc_id):\n",
    "        return self.es.get(index=self.index_name, id=doc_id)['_source']\n",
    "\n",
    "    def search(self, query, *args):\n",
    "        get_score(self.es.search(index=self.index_name, body=query, size=1000))\n",
    "        # note that size set to 20 just because default value is 10 and we know that we have 12 docs and 10 < 12 < 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query:\n",
    "    def __init__(self, task_id, query, relevance):\n",
    "        self.task_id = task_id\n",
    "        self.query = query\n",
    "        self.relevance = relevance\n",
    "\n",
    "    def json_query(self):\n",
    "        return {\n",
    "            'query': {\n",
    "                'bool': {\n",
    "                    'should': [\n",
    "                        {\n",
    "                            'match': {\n",
    "                                'text': self.query\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchQualityChecker:\n",
    "    def __init__(self, queries, index):\n",
    "        self.queries = queries\n",
    "        self.index = index\n",
    "        self.results = {}\n",
    "\n",
    "    def search(self):\n",
    "        self.results = {}\n",
    "        for query in self.queries:\n",
    "            actual = self.index.search(query.json_query())\n",
    "            self.results[query.task_id] = [(actual[k], query.relevance[k]) for k in query.relevance]\n",
    "\n",
    "    def r2(self):\n",
    "        for query in self.queries:\n",
    "            r2 = r2_score(self.results[query.task_id][1], self.results[query.task_id][0])\n",
    "            print(f\"Task {query.task_id}, r2={r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevance():\n",
    "    res = {}\n",
    "    xml_tree = etree.parse(\"D:\\\\IR-2019\\\\ir1\\\\data\\\\or_relevant-minus_table.xml\")\n",
    "    root = xml_tree.getroot()\n",
    "    for task in root.getchildren():\n",
    "        relevance = {}\n",
    "        for document in task.getchildren():\n",
    "            relevance[document.get(\"id\")] = document.get(\"relevance\")\n",
    "        res[task.get(\"id\")] = relevance\n",
    "    print(len(res))\n",
    "    return res\n",
    "\n",
    "\n",
    "def generate_queries_plain_texts():\n",
    "    relevances = get_relevance()\n",
    "    xml_tree = etree.parse(\"D:\\\\IR-2019\\\\ir1\\\\data\\\\web2008_adhoc.xml\")\n",
    "    root = xml_tree.getroot()\n",
    "    res = []\n",
    "    for task in root.getchildren():\n",
    "        if task.get(\"id\") is not None:\n",
    "            for query_text in task.getchildren():\n",
    "                try:\n",
    "                    res.append(Query(task.get(\"id\"), query_text.text, relevances[task.get(\"id\")]))\n",
    "                except:\n",
    "                    pass\n",
    "    print(len(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_1 = {\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            'text': {\n",
    "                'type': 'text'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d6eca1b4fc4c8c939b24a4dc283c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = Index(\"docs\", settings_1)\n",
    "start = time.time()\n",
    "index.add_documents()\n",
    "print(time.time() - start)\n",
    "\n",
    "queries = generate_queries_plain_texts()\n",
    "sqc = SearchQualityChecker(queries, index)\n",
    "sqc.search()\n",
    "print(sqc.r2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"D:\\\\IR-2019\\\\ir1\\\\res\\\\json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
